{
  "id": "code-25",
  "title": "Project setup guide",
  "category": "coding",
  "goal": "Provide a clear outline of folder structure and setup steps for a full-stack project using specified frontend and backend frameworks.",
  "prompt": "Outline the folder structure and setup steps for a {project_type} project that uses {frontend_framework} for the frontend and {backend_framework} for the backend.",
  "variables": ["project_type", "frontend_framework", "backend_framework"],
  "tags": ["project-setup", "full-stack", "frontend", "backend"],
  "models_tested": ["gpt-5", "gemini-2.5", "claude-3"],
  "responses": {
    "gpt-5": "Here‚Äôs a **complete folder structure** and **step-by-step setup guide** for a **Voice Assistant project** that uses **React (frontend)** and **Node.js + Express (backend)** ‚Äî suitable for real-time speech recognition, text-to-speech, and AI response integration later.\n\n---\n\n## üóÇÔ∏è Folder Structure\n\n```\nvoice-assistant/\n‚îÇ\n‚îú‚îÄ‚îÄ client/                     # React frontend\n‚îÇ   ‚îú‚îÄ‚îÄ public/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html\n‚îÇ   ‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VoiceCapture.jsx\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatWindow.jsx\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SpeakingIndicator.jsx\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useMicrophone.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Home.jsx\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ main.css\n‚îÇ   ‚îú‚îÄ‚îÄ package.json\n‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js or webpack.config.js (if using Vite or CRA)\n‚îÇ\n‚îú‚îÄ‚îÄ server/                     # Node.js + Express backend\n‚îÇ   ‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aiRoutes.js\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ audioRoutes.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sttService.js        # Speech-to-Text logic\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ttsService.js        # Text-to-Speech logic\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ aiService.js         # AI reply generator\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ env.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.js\n‚îÇ   ‚îú‚îÄ‚îÄ package.json\n‚îÇ   ‚îî‚îÄ‚îÄ .env\n‚îÇ\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ package.json                  # optional root-level config for running both with concurrently\n```\n\n---\n\n## ‚öôÔ∏è Step-by-Step Setup Guide\n\n### üß© 1. Create the project root\n\n```bash\nmkdir voice-assistant\ncd voice-assistant\n```\n\n---\n\n### üñ•Ô∏è 2. Setup the **React frontend**\n\n```bash\nnpx create-react-app client\n# or with Vite for faster dev\n# npm create vite@latest client -- --template react\n```\n\nThen:\n\n```bash\ncd client\nnpm install socket.io-client\nnpm install --save-dev tailwindcss postcss autoprefixer\nnpx tailwindcss init -p\n```\n\nUpdate **`tailwind.config.js`**:\n\n```js\ncontent: [\"./index.html\", \"./src/**/*.{js,jsx,ts,tsx}\"],\ntheme: { extend: {} },\nplugins: [],\n```\n\nAdd Tailwind imports to `src/index.css`:\n\n```css\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n```\n\n---\n\n### ‚öôÔ∏è 3. Setup the **Node.js backend**\n\nBack to the root folder:\n\n```bash\ncd ..\nmkdir server\ncd server\nnpm init -y\nnpm install express cors dotenv socket.io\n```\n\n---\n\n### üì¶ 4. Basic backend setup\n\n#### `server/src/app.js`\n\n```js\nimport express from \"express\";\nimport cors from \"cors\";\nimport { createServer } from \"http\";\nimport { Server } from \"socket.io\";\n\nconst app = express();\napp.use(cors());\napp.use(express.json());\n\n// REST endpoints\napp.get(\"/\", (req, res) => res.send(\"Voice Assistant Backend Running\"));\n\nconst httpServer = createServer(app);\nconst io = new Server(httpServer, {\n  cors: { origin: \"*\" },\n});\n\nio.on(\"connection\", (socket) => {\n  console.log(\"Client connected:\", socket.id);\n\n  socket.on(\"audio_chunk\", (data) => {\n    console.log(\"Received audio chunk\", data.length);\n    // TODO: Forward to STT / AI / TTS\n  });\n\n  socket.on(\"disconnect\", () => console.log(\"Client disconnected\"));\n});\n\nexport { app, httpServer };\n```\n\n#### `server/src/server.js`\n\n```js\nimport { httpServer } from \"./app.js\";\n\nconst PORT = process.env.PORT || 5000;\nhttpServer.listen(PORT, () => console.log(`Server listening on port ${PORT}`));\n```\n\n---\n\n### üß† 5. Connect frontend to backend via WebSocket\n\nIn **`client/src/components/VoiceCapture.jsx`**:\n\n```jsx\nimport { useEffect, useRef, useState } from \"react\";\nimport io from \"socket.io-client\";\n\nconst socket = io(\"http://localhost:5000\");\n\nexport default function VoiceCapture() {\n  const [recording, setRecording] = useState(false);\n  const mediaRecorderRef = useRef(null);\n\n  const toggleRecording = async () => {\n    if (!recording) {\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      mediaRecorderRef.current = new MediaRecorder(stream, { mimeType: \"audio/webm\" });\n      mediaRecorderRef.current.ondataavailable = (e) => socket.emit(\"audio_chunk\", e.data);\n      mediaRecorderRef.current.start(250);\n      setRecording(true);\n    } else {\n      mediaRecorderRef.current.stop();\n      setRecording(false);\n    }\n  };\n\n  return (\n    <div className=\"flex flex-col items-center gap-4 p-4\">\n      <button\n        onClick={toggleRecording}\n        className={`px-6 py-3 rounded-full text-white ${recording ? \"bg-red-500\" : \"bg-blue-500\"}`}\n      >\n        {recording ? \"Stop Recording\" : \"Start Recording\"}\n      </button>\n    </div>\n  );\n}\n```\n\n---\n\n### üß© 6. Combine frontend + backend for development\n\nAt the root folder:\n\n```bash\nnpm init -y\nnpm install concurrently\n```\n\n#### `package.json` (root)\n\n```json\n{\n  \"name\": \"voice-assistant\",\n  \"scripts\": {\n    \"start\": \"concurrently \\\"npm run dev --prefix client\\\" \\\"npm start --prefix server\\\"\"\n  }\n}\n```\n\nThen run:\n\n```bash\nnpm start\n```\n\n‚úÖ This will:\n\n* Start the **React app** on `http://localhost:5173` (Vite) or `http://localhost:3000`\n* Start the **Express server** on `http://localhost:5000`\n\n---\n\n### üîß 7. Optional Add-ons\n\n| Feature | Where | Library/Tool |\n|----------|--------|--------------|\n| Speech-to-Text | Backend | `whisper`, `whisper-timestamped`, or `@google-cloud/speech` |\n| Text-to-Speech | Backend | `gtts`, `openai/audio`, or `elevenlabs` |\n| AI Chat Responses | Backend | `openai`, `gemini`, or local LLM |\n| Waveform visualization | Frontend | `wavesurfer.js` or `@react-audio/visualizer` |\n| Real-time playback | Frontend | `AudioContext`, `AudioBuffer`, or WebRTC |\n\n---\n\n## üöÄ Summary\n\n| Layer | Tech | Purpose |\n|--------|------|----------|\n| **Frontend** | React + Tailwind + Socket.IO Client | Capture mic input, show UI, play TTS |\n| **Backend** | Node.js + Express + Socket.IO Server | Handle streaming audio, AI processing |\n| **Communication** | WebSocket (Socket.IO) | Real-time bidirectional data |\n| **Next Steps** | Add Whisper STT + OpenAI/Gemini + TTS | Make it fully conversational |\n\n---\n\nWould you like me to extend this with **real-time TTS playback** and **AI reply integration (dummy or OpenAI)** next?",
    "gemini-2.5": "üéôÔ∏è Voice Assistant Project Structure Outline\n\nThis structure uses a monorepo approach, organizing the React client and the Node.js/Express server into two main subdirectories under a single root project folder.\n\n1. Top-Level Structure\n\nvoice-assistant-app/\n‚îú‚îÄ‚îÄ client/          <-- React Frontend (User Interface)\n‚îú‚îÄ‚îÄ server/          <-- Node.js/Express Backend (API and Logic)\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ package.json     <-- For root-level scripts (e.g., 'npm run dev')\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ LICENSE\n\n2. Server (Node.js/Express) Structure\n\nvoice-assistant-app/server/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ routes/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ voice.js\n‚îÇ   ‚îú‚îÄ‚îÄ controllers/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ voiceController.js\n‚îÇ   ‚îú‚îÄ‚îÄ middleware/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cors.js\n‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nlpService.js\n‚îÇ   ‚îî‚îÄ‚îÄ app.js\n‚îú‚îÄ‚îÄ package.json\n‚îú‚îÄ‚îÄ .env\n‚îî‚îÄ‚îÄ server.js\n\n3. Client (React) Structure\n\nvoice-assistant-app/client/\n‚îú‚îÄ‚îÄ public/\n‚îÇ   ‚îî‚îÄ‚îÄ index.html\n‚îî‚îÄ‚îÄ src/\n    ‚îú‚îÄ‚îÄ components/\n    ‚îÇ   ‚îú‚îÄ‚îÄ AssistantDisplay.jsx\n    ‚îÇ   ‚îú‚îÄ‚îÄ MicrophoneButton.jsx\n    ‚îÇ   ‚îî‚îÄ‚îÄ Layout.jsx\n    ‚îú‚îÄ‚îÄ hooks/\n    ‚îÇ   ‚îî‚îÄ‚îÄ useRecorder.js\n    ‚îú‚îÄ‚îÄ api/\n    ‚îÇ   ‚îî‚îÄ‚îÄ voiceApi.js\n    ‚îú‚îÄ‚îÄ styles/\n    ‚îÇ   ‚îî‚îÄ‚îÄ index.css\n    ‚îî‚îÄ‚îÄ App.jsx\n\n4. Initial Setup Steps\n\nStep 1: Initialize the Root Project\n\n```bash\nmkdir voice-assistant-app\ncd voice-assistant-app\nmkdir client server\n```\n\nStep 2: Set up the Backend\n\n```bash\ncd server\nnpm init -y\nnpm install express cors body-parser dotenv\n```\n\nStep 3: Set up the Frontend\n\n```bash\ncd ../client\nnpm create vite@latest . -- --template react\nnpm install\n```\n\nStep 4: Add Root Scripts\n\n```json\n{\n  \"scripts\": {\n    \"start:server\": \"cd server && node server.js\",\n    \"start:client\": \"cd client && npm run dev\",\n    \"dev\": \"concurrently \\\"npm run start:server\\\" \\\"npm run start:client\\\"\",\n    \"install:all\": \"npm install --prefix client && npm install --prefix server\"\n  }\n}\n```",
    "claude-3": "# Voice Assistant Project Structure\n\n## Folder Structure\n\n```\nvoice-assistant/\n‚îú‚îÄ‚îÄ frontend/\n‚îÇ   ‚îú‚îÄ‚îÄ public/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.html\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ favicon.ico\n‚îÇ   ‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VoiceInput.jsx\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OutputDisplay.jsx\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CommandHistory.jsx\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Settings.jsx\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useVoiceRecognition.js\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useAudioPlayback.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ styles/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.css\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.js\n‚îÇ   ‚îú‚îÄ‚îÄ package.json\n‚îÇ   ‚îî‚îÄ‚îÄ .env.local\n‚îÇ\n‚îú‚îÄ‚îÄ backend/\n‚îÇ   ‚îú‚îÄ‚îÄ routes/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.js\n‚îÇ   ‚îú‚îÄ‚îÄ controllers/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voiceController.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ commandController.js\n‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speechRecognition.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ textToSpeech.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ externalApis.js\n‚îÇ   ‚îú‚îÄ‚îÄ middleware/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ errorHandler.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.js\n‚îÇ   ‚îú‚îÄ‚îÄ models/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Command.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ User.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VoiceSession.js\n‚îÇ   ‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ helpers.js\n‚îÇ   ‚îú‚îÄ‚îÄ config/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.js\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constants.js\n‚îÇ   ‚îú‚îÄ‚îÄ server.js\n‚îÇ   ‚îú‚îÄ‚îÄ package.json\n‚îÇ   ‚îú‚îÄ‚îÄ .env\n‚îÇ   ‚îî‚îÄ‚îÄ .gitignore\n‚îÇ\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ docker-compose.yml\n```\n\n## Setup Steps\n\n1. **Create directories** using `mkdir voice-assistant && cd voice-assistant`\n2. **Setup backend:** `npm init -y && npm install express cors dotenv axios`\n3. **Setup frontend:** `npx create-react-app frontend && npm install axios`\n4. **Configure .env files**\n5. **Run both:** `npm run dev` with concurrently\n\nThis structure ensures clear separation between UI and API layers and supports scalable feature growth."
  },
  "last_updated": "2025-11-03"
}
