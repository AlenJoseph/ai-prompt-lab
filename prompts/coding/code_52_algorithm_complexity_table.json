{
  "id": "code-52",
  "title": "Algorithm Complexity Table",
  "category": "coding",
  "goal": "Create a table listing common algorithms with their space and time complexities",
  "prompt": "Create a table listing algorithms and their space and time complexities. Include columns: Algorithm name, Best case time complexity, Worst case time complexity, Average case time complexity, Space complexity, Examples.",
  "variables": [],
  "tags": ["algorithm-complexity", "programming", "education"],
  "models_tested": ["gpt-5", "gemini-2.5", "claude-3"],
  "responses": {
    "gpt-5": "Hereâ€™s a comprehensive table summarizing common algorithms with their time and space complexities:\n\n| Algorithm Name             | Best Case Time Complexity | Worst Case Time Complexity | Average Case Time Complexity | Space Complexity | Examples / Notes                                   |\n| -------------------------- | ------------------------- | -------------------------- | ---------------------------- | ---------------- | -------------------------------------------------- |\n| **Bubble Sort**            | O(n)                      | O(nÂ²)                      | O(nÂ²)                        | O(1)             | Sorting small arrays, simple implementation        |\n| **Selection Sort**         | O(nÂ²)                     | O(nÂ²)                      | O(nÂ²)                        | O(1)             | Sorting small arrays, fewer swaps than bubble sort |\n| **Insertion Sort**         | O(n)                      | O(nÂ²)                      | O(nÂ²)                        | O(1)             | Efficient for nearly sorted arrays                 |\n| **Merge Sort**             | O(n log n)                | O(n log n)                 | O(n log n)                   | O(n)             | Large datasets, stable sort                        |\n| **Quick Sort**             | O(n log n)                | O(nÂ²)                      | O(n log n)                   | O(log n)         | Widely used, divide and conquer                    |\n| **Heap Sort**              | O(n log n)                | O(n log n)                 | O(n log n)                   | O(1)             | Priority queues, in-place                          |\n| **Counting Sort**          | O(n + k)                  | O(n + k)                   | O(n + k)                     | O(k)             | Non-comparison sort, integers in small range       |\n| **Radix Sort**             | O(nk)                     | O(nk)                      | O(nk)                        | O(n + k)         | Sorting integers or strings, stable                |\n| **Binary Search**          | O(1)                      | O(log n)                   | O(log n)                     | O(1)             | Searching in sorted arrays                         |\n| **Linear Search**          | O(1)                      | O(n)                       | O(n)                         | O(1)             | Searching unsorted arrays                          |\n| **DFS (Graph Traversal)**  | O(V + E)                  | O(V + E)                   | O(V + E)                     | O(V)             | Traversing graphs, recursive or stack-based        |\n| **BFS (Graph Traversal)**  | O(V + E)                  | O(V + E)                   | O(V + E)                     | O(V)             | Shortest path in unweighted graphs                 |\n| **Dijkstra's Algorithm**   | O(E + V log V)            | O(E + V log V)             | O(E + V log V)               | O(V + E)         | Shortest path, weighted graphs                     |\n| **Bellman-Ford Algorithm** | O(VE)                     | O(VE)                      | O(VE)                        | O(V)             | Shortest path, handles negative weights            |\n| **Floyd-Warshall**         | O(VÂ³)                     | O(VÂ³)                      | O(VÂ³)                        | O(VÂ²)            | All pairs shortest path, dynamic programming       |\n| **Quickselect**            | O(n)                      | O(nÂ²)                      | O(n)                         | O(1)             | Find k-th smallest element                         |\n| **Kruskalâ€™s MST**          | O(E log E)                | O(E log E)                 | O(E log E)                   | O(V)             | Minimum spanning tree                              |\n| **Primâ€™s MST**             | O(E + V log V)            | O(E + V log V)             | O(E + V log V)               | O(V + E)         | Minimum spanning tree                              |\n\n**Legend / Notes:**\n\n* `n` = number of elements, `V` = number of vertices, `E` = number of edges, `k` = range of input values (for counting/radix sort).\n* Space complexity is **auxiliary space** unless otherwise noted.\n* Best case may differ based on input (e.g., already sorted arrays for insertion/bubble sort).",
    "gemini-2.5": "Certainly! Here is a table listing the time and space complexities for several common algorithms, including sorting, searching, and graph algorithms.\n\n## ðŸ’» Algorithm Complexities (Time and Space)\n\nThis table uses N as the size of the input (e.g., number of elements in an array or vertices/edges in a graph). The time complexities are typically expressed using Big O notation (O), which represents the worst-case scenario, though the table includes best and average cases where they differ significantly.\n\n| Algorithm Name | Best Case Time Complexity | Worst Case Time Complexity | Average Case Time Complexity | Space Complexity (Worst Case) | Examples |\n| :--- | :--- | :--- | :--- | :--- | :--- |\n| **Sorting** | | | | | |\n| **Quick Sort** | O(N log N) | O(N^2) | O(N log N) | O(log N) (Auxiliary) | Sorting an array in memory. |\n| **Merge Sort** | O(N log N) | O(N log N) | O(N log N) | O(N) (Auxiliary) | External sorting, stable sorting needs. |\n| **Heap Sort** | O(N log N) | O(N log N) | O(N log N) | O(1) | Sorting large data when space is limited. |\n| **Bubble Sort** | O(N) | O(N^2) | O(N^2) | O(1) | Educational examples, sorting nearly sorted data. |\n| **Insertion Sort** | O(N) | O(N^2) | O(N^2) | O(1) | Sorting small arrays, or as part of more complex sorts (like Timsort). |\n| **Selection Sort** | O(N^2) | O(N^2) | O(N^2) | O(1) | Simple in-place sorting, minimal swaps. |\n| **Searching** | | | | | |\n| **Linear Search** | O(1) | O(N) | O(N) | O(1) | Searching an unsorted list/array. |\n| **Binary Search** | O(1) | O(log N) | O(log N) | O(1) (Iterative) or O(log N) (Recursive) | Searching in a sorted array or list (e.g., dictionary lookup). |\n| **Graph** | | | | | |\n| **Breadth-First Search (BFS)** | O(1) | O(V+E) | O(V+E) | O(V) | Finding the shortest path in an unweighted graph, web crawlers. |\n| **Depth-First Search (DFS)** | O(1) | O(V+E) | O(V+E) | O(V) | Checking connectivity, topological sorting. |\n| **Dijkstra's Algorithm** | O(E log V) (using a heap) | O(E log V) | O(E log V) | O(V+E) | Finding the shortest path in a weighted graph with non-negative edge weights (e.g., GPS). |\n\n### Key Terminology\n\n* **Time Complexity:** Measures the amount of time taken by an algorithm to run as a function of the input length (N).\n    * **Best Case:** The most favorable input (e.g., an already sorted array for Bubble Sort).\n    * **Worst Case:** The least favorable input (e.g., a reverse-sorted array for Bubble Sort).\n    * **Average Case:** The expected running time over all possible inputs.\n* **Space Complexity:** Measures the amount of memory (space) taken by an algorithm, usually focusing on auxiliary space (extra space used beyond the input).\n    * O(1): Constant time/space. Does not change with input size.\n    * O(log N): Logarithmic time/space. Typically seen when the search space is halved in each step.\n    * O(N): Linear time/space. Scales directly with the input size.\n    * O(N log N): Linearithmic time. Common in efficient comparison sorting.\n    * O(N^2): Quadratic time/space. Often involves nested loops over the input.\n* V: Number of vertices (nodes) in a graph.\n* E: Number of edges (connections) in a graph.\n\nWould you like me to add more algorithms, such as those related to dynamic programming or string matching, or perhaps focus more on the complexity notations themselves?",
    "claude-3": "| Algorithm Name | Best Case Time | Worst Case Time | Average Case Time | Space Complexity | Examples |\n|---|---|---|---|---|---|\n| **Sorting Algorithms** | | | | | |\n| Bubble Sort | O(n) | O(nÂ²) | O(nÂ²) | O(1) | Simple sorting, educational purposes |\n| Selection Sort | O(nÂ²) | O(nÂ²) | O(nÂ²) | O(1) | Minimal memory environments |\n| Insertion Sort | O(n) | O(nÂ²) | O(nÂ²) | O(1) | Small datasets, nearly sorted data |\n| Merge Sort | O(n log n) | O(n log n) | O(n log n) | O(n) | Large datasets, guaranteed performance |\n| Quick Sort | O(n log n) | O(nÂ²) | O(n log n) | O(log n) | General-purpose sorting, average performance |\n| Heap Sort | O(n log n) | O(n log n) | O(n log n) | O(1) | Guaranteed O(n log n), in-place sorting |\n| Counting Sort | O(n + k) | O(n + k) | O(n + k) | O(k) | Integers with limited range |\n| Radix Sort | O(nk) | O(nk) | O(nk) | O(n + k) | Sorting integers, strings with fixed length |\n| **Searching Algorithms** | | | | | |\n| Linear Search | O(1) | O(n) | O(n) | O(1) | Unordered data, linked lists |\n| Binary Search | O(1) | O(log n) | O(log n) | O(1) | Sorted arrays, large datasets |\n| **Graph Algorithms** | | | | | |\n| Breadth-First Search (BFS) | O(V + E) | O(V + E) | O(V + E) | O(V) | Shortest path in unweighted graphs, level-order traversal |\n| Depth-First Search (DFS) | O(V + E) | O(V + E) | O(V + E) | O(V) | Topological sorting, cycle detection |\n| Dijkstra's Algorithm | O((V + E) log V) | O((V + E) log V) | O((V + E) log V) | O(V) | Shortest path in weighted graphs |\n| Bellman-Ford | O(VE) | O(VE) | O(VE) | O(V) | Shortest path with negative weights |\n| Floyd-Warshall | O(VÂ³) | O(VÂ³) | O(VÂ³) | O(VÂ²) | All-pairs shortest paths |\n| Kruskal's Algorithm | O(E log E) | O(E log E) | O(E log E) | O(V) | Minimum spanning tree |\n| Prim's Algorithm | O(VÂ²) | O(VÂ²) | O(VÂ²) | O(V) | Minimum spanning tree, dense graphs |\n| **Dynamic Programming** | | | | | |\n| Fibonacci (Memoization) | O(n) | O(n) | O(n) | O(n) | Computing Fibonacci numbers |\n| Longest Common Subsequence | O(mn) | O(mn) | O(mn) | O(mn) | String matching, sequence alignment |\n| 0/1 Knapsack | O(nW) | O(nW) | O(nW) | O(nW) | Resource allocation, optimization |\n| **String Algorithms** | | | | | |\n| Naive String Matching | O(n) | O((n-m+1)m) | O(nm) | O(1) | Small patterns, simple implementation |\n| KMP (Knuth-Morris-Pratt) | O(n + m) | O(n + m) | O(n + m) | O(m) | Pattern matching, reliable performance |\n| Boyer-Moore | O(n/m) | O(nm) | O(n) | O(m + Ïƒ) | Large alphabets, practical performance |\n| Rabin-Karp | O(n + m) | O(nm) | O(n + m) | O(1) | Multiple pattern matching |\n| **Tree Algorithms** | | | | | |\n| Binary Search Tree Lookup | O(log n) | O(n) | O(log n) | O(1) | Balanced BSTs for searching |\n| AVL Tree Operations | O(log n) | O(log n) | O(log n) | O(n) | Self-balancing trees, guaranteed balance |\n| Red-Black Tree Operations | O(log n) | O(log n) | O(log n) | O(n) | Java TreeMap, C++ STL, slightly faster insertions |\n| B-Tree Operations | O(log n) | O(log n) | O(log n) | O(n) | Database indexing, file systems |\n| **Other Algorithms** | | | | | |\n| Hash Table Lookup | O(1) | O(n) | O(1) | O(n) | Caching, fast lookups |\n| Binary Exponentiation | O(log n) | O(log n) | O(log n) | O(log n) | Computing large powers modulo |\n| Euclidean Algorithm (GCD) | O(log(min(a,b))) | O(log(min(a,b))) | O(log(min(a,b))) | O(1) | Finding greatest common divisor |"
  },
  "last_updated": "2025-11-03"
}
